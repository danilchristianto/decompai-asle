{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available and set the device accordingly\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# Load tokenizer and model from Hugging Face Hub and move model to the MPS device if available\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LLM4Binary/llm4decompile-6.7b-v1.5\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"LLM4Binary/llm4decompile-6.7b-v1.5\")\n",
    "\n",
    "# Convert model to FP16 to reduce memory usage\n",
    "model = model.half().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the workspace directory within the repository for intermediate files\n",
    "WORKSPACE_DIR = \"decompile_workspace\"\n",
    "\n",
    "# Ensure the workspace directory exists\n",
    "os.makedirs(WORKSPACE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_function_asm(disassemble_path, function_name):\n",
    "    # Extract the specified function's assembly\n",
    "    input_asm = ''\n",
    "    with open(disassemble_path, 'r') as f:\n",
    "        asm = f.read()\n",
    "        if f'<{function_name}>:' not in asm:\n",
    "            raise ValueError(f\"Function {function_name} not found in the assembly.\")\n",
    "        # Isolate the assembly for the specified function\n",
    "        asm = f'<{function_name}>:' + asm.split(f'<{function_name}>:')[-1].split('\\n\\n')[0]\n",
    "        asm_clean = \"\"\n",
    "        for line in asm.splitlines():\n",
    "            if len(line.split(\"\\t\")) < 3 and '00' in line:\n",
    "                continue\n",
    "            # Remove binary codes and comments\n",
    "            asm_clean += \"\\t\".join(line.split(\"\\t\")[2:]).split(\"#\")[0].strip() + \"\\n\"\n",
    "    input_asm = asm_clean.strip()\n",
    "    return input_asm\n",
    "\n",
    "def compile(target: str, c_code_path: str, binary_path: str):\n",
    "    if target == \"mac\":\n",
    "        # Compile locally on macOS\n",
    "        compile_command = f\"gcc -o {binary_path}.o {c_code_path} -lm\"\n",
    "        subprocess.run(compile_command, shell=True, check=True)\n",
    "    else:\n",
    "        # Use Docker for cross-platform compilation (Linux x86_64)\n",
    "        docker_image = \"gcc_linux_x86_64:latest\"\n",
    "        container_name = \"c_code_compiler\"\n",
    "        \n",
    "        # Build Docker image targeting linux/amd64 architecture\n",
    "        docker_build_command = (\n",
    "            f\"docker buildx build --platform linux/amd64 \"\n",
    "            f\"-t {docker_image} . --load\"\n",
    "        )\n",
    "        docker_run_command = (\n",
    "            f\"docker run --rm --name {container_name} \"\n",
    "            f\"-v {os.getcwd()}:/workspace {docker_image} \"\n",
    "            f\"gcc -o /workspace/{binary_path}.o /workspace/{c_code_path} -lm\"\n",
    "        )\n",
    "        \n",
    "        # Build Docker image\n",
    "        subprocess.run(docker_build_command, shell=True, check=True)\n",
    "        # Compile using Docker\n",
    "        subprocess.run(docker_run_command, shell=True, check=True)\n",
    "\n",
    "def disassemble_binary(binary_path, function_name, target: str):\n",
    "    # Disassemble the binary directly\n",
    "    disassemble_path = os.path.join(WORKSPACE_DIR, \"disassembled_code.asm\")\n",
    "    \n",
    "    if target == \"mac\":\n",
    "        # Disassemble locally\n",
    "        disassemble_command = [\"objdump\", \"-d\", binary_path]\n",
    "        result = subprocess.run(disassemble_command, capture_output=True, text=True, check=True)\n",
    "    else:\n",
    "        # Use Docker for disassembly\n",
    "        docker_image = \"gcc_linux_x86_64:latest\"\n",
    "        container_name = \"disassembler\"\n",
    "        \n",
    "        docker_run_command = (\n",
    "            f\"docker run --rm --name {container_name} \"\n",
    "            f\"-v {os.getcwd()}:/workspace {docker_image} \"\n",
    "            f\"objdump -d /workspace/{binary_path}.o\"\n",
    "        )\n",
    "        result = subprocess.run(docker_run_command, shell=True, capture_output=True, text=True, check=True)\n",
    "\n",
    "    # Save disassembled code to a file for inspection\n",
    "    with open(disassemble_path, \"w\") as f:\n",
    "        f.write(result.stdout)\n",
    "        \n",
    "    input_asm = extract_function_asm(disassemble_path, function_name)\n",
    "    \n",
    "    return input_asm\n",
    "\n",
    "\n",
    "def compile_and_disassemble_c_code(c_code_path, function_name):\n",
    "    binary_path = os.path.join(WORKSPACE_DIR, \"compiled_binary\")\n",
    "    target = \"linux\"\n",
    "    \n",
    "    if target == \"mac\":\n",
    "        function_name = \"_\" + function_name\n",
    "\n",
    "    # Compile the C code\n",
    "    compile(target, c_code_path, binary_path)\n",
    "\n",
    "    # Disassemble the binary\n",
    "    input_asm = disassemble_binary(binary_path, function_name, target)\n",
    "    \n",
    "    return input_asm\n",
    "\n",
    "def decompile_with_llm4decompile(disassembled_code):\n",
    "    # Tokenize the input text and add attention mask\n",
    "    inputs = tokenizer(disassembled_code, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    # Setting pad_token_id to eos_token_id, since this is the default behavior for many generative models\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "    # Print the number of tokens in the input\n",
    "    print(f\"Number of tokens in input: {inputs.input_ids.size(1)}\")\n",
    "    \n",
    "    # Generate decompiled code with attention mask\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_new_tokens=200\n",
    "    )\n",
    "    decompiled_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Save the decompiled code for inspection\n",
    "    decompiled_path = os.path.join(WORKSPACE_DIR, \"decompiled_code.c\")\n",
    "    with open(decompiled_path, \"w\") as f:\n",
    "        f.write(decompiled_code)\n",
    "    \n",
    "    return decompiled_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(input_path, function_name):\n",
    "    # Copy the C code or binary to the workspace for reference\n",
    "    input_basename = os.path.basename(input_path)\n",
    "    workspace_input_path = os.path.join(WORKSPACE_DIR, input_basename)\n",
    "    if not os.path.exists(workspace_input_path):\n",
    "        os.system(f\"cp {input_path} {workspace_input_path}\")\n",
    "    \n",
    "    try:\n",
    "        if input_path.endswith(\".c\"):\n",
    "            print(\"Input detected as C code. Compiling and disassembling...\")\n",
    "            disassembled_code = compile_and_disassemble_c_code(input_path, function_name)\n",
    "        else:\n",
    "            print(\"Input detected as binary. Disassembling...\")\n",
    "            disassembled_code = disassemble_binary(input_path, function_name)\n",
    "        \n",
    "        print(\"\\nDisassembled Code:\")\n",
    "        print(disassembled_code)\n",
    "        \n",
    "        prompt = f\"# This is the assembly code:\\n{disassembled_code}\\n# What is the source code?\\n\"\n",
    "        \n",
    "        # Decompile with LLM4Decompile\n",
    "        print(\"\\nDecompiling...\")\n",
    "        decompiled_code = decompile_with_llm4decompile(prompt)\n",
    "        \n",
    "        # Remove input from the decompiled code\n",
    "        decompiled_code = decompiled_code[len(prompt):].strip()\n",
    "        \n",
    "        print(\"\\nDecompiled Code:\")\n",
    "        print(decompiled_code)\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_code_path = \"c_code/fibonacci.c\"\n",
    "function_name = \"func0\"\n",
    "process_file(c_code_path, function_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4decompile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
